{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# 📁 Klasör yolları\n",
        "original_train_path = \"/content/drive/MyDrive/Alzheimer_dataset/Splitted_OriginalDataset/train\"\n",
        "augmented_dir = \"/content/drive/MyDrive/Alzheimer_dataset/Custom_Augmented_Train\"\n",
        "os.makedirs(augmented_dir, exist_ok=True)\n",
        "\n",
        "# ✅ Augmentasyon sadece bu sınıflara uygulanacak\n",
        "target_classes = ['ModerateDemented', 'MildDemented']\n",
        "\n",
        "# 🔄 Augmentasyon ayarları\n",
        "augmenter = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# ✨ Her sınıftan görüntüler augment edilir ve kaydedilir\n",
        "for class_name in target_classes:\n",
        "    source_dir = os.path.join(original_train_path, class_name)\n",
        "    save_dir = os.path.join(augmented_dir, class_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    files = os.listdir(source_dir)[:20]  # Örnek: ilk 20 görüntü\n",
        "    for fname in files:\n",
        "        img_path = os.path.join(source_dir, fname)\n",
        "        img = load_img(img_path, target_size=(176, 208))\n",
        "        x = img_to_array(img)\n",
        "        x = x.reshape((1,) + x.shape)\n",
        "\n",
        "        prefix = fname.split('.')[0]\n",
        "        for i, batch in enumerate(augmenter.flow(x, batch_size=1, save_to_dir=save_dir,\n",
        "                                                 save_prefix=prefix, save_format='jpg')):\n",
        "            if i >= 5:  # Her bir görselden 5 tane yeni üret\n",
        "                break\n"
      ],
      "metadata": {
        "id": "DldLNMSO5e-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Updated import statement to reflect the Keras 3 API changes.\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# 📁 Veri seti yolları\n",
        "train_dir = \"/content/drive/MyDrive/Alzheimer_dataset/Splitted_OriginalDataset/train\"\n",
        "val_dir = \"/content/drive/MyDrive/Alzheimer_dataset/Splitted_OriginalDataset/val\"\n",
        "test_dir = \"/content/drive/MyDrive/Alzheimer_dataset/Splitted_OriginalDataset/test\"\n",
        "\n",
        "# 🔄 Veri hazırlığı ve artırma\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Görüntülerin normalize edilmesi\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=(176, 208), batch_size=32, class_mode='sparse', color_mode='rgb'\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir, target_size=(176, 208), batch_size=32, class_mode='sparse', color_mode='rgb'\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=(176, 208), batch_size=32, class_mode='sparse', color_mode='rgb'\n",
        ")\n",
        "\n",
        "# 🏗️ Model yapısı (VGG19)\n",
        "base_model = VGG19(include_top=False, weights='imagenet', input_shape=(176, 208, 3))\n",
        "base_model.trainable = False  # İlk başta sadece üst katmanları eğiteceğiz\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "# 📉 Callbacks\n",
        "tensorboard_cb = TensorBoard(log_dir='/content/drive/MyDrive/Alzheimer_dataset/logs')\n",
        "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# 🎯 Sınıf ağırlıkları hesaplama\n",
        "# 🎯 Sınıf ağırlıkları hesaplama\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),  # Changed to np.unique(train_generator.classes) to get unique class labels as a NumPy array\n",
        "    y=train_generator.classes\n",
        ")\n",
        "\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# 🚀 Modeli eğit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[tensorboard_cb, early_stopping_cb]\n",
        ")\n",
        "\n",
        "# 🎯 Model değerlendirmesi\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
        "\n",
        "# 🎯 Test verisi üzerinde tahmin ve sonuç raporu\n",
        "test_predictions = model.predict(test_generator)\n",
        "test_predictions = tf.argmax(test_predictions, axis=1)\n",
        "print(classification_report(test_generator.classes, test_predictions))\n",
        "\n",
        "# 💾 Modeli kaydet\n",
        "model.save(\"/content/drive/MyDrive/Alzheimer_dataset/final_model_vgg19.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrP3YVGKBwTe",
        "outputId": "2bed847c-00b8-4c12-d5ad-a0b8644801d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4479 images belonging to 4 classes.\n",
            "Found 960 images belonging to 4 classes.\n",
            "Found 961 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 570ms/step - accuracy: 0.3049 - loss: 2.9330 - val_accuracy: 0.3667 - val_loss: 1.3768\n",
            "Epoch 2/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 495ms/step - accuracy: 0.4318 - loss: 1.1664 - val_accuracy: 0.5031 - val_loss: 1.0134\n",
            "Epoch 3/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 480ms/step - accuracy: 0.4729 - loss: 1.1582 - val_accuracy: 0.5521 - val_loss: 0.8927\n",
            "Epoch 4/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 479ms/step - accuracy: 0.5172 - loss: 1.1013 - val_accuracy: 0.3531 - val_loss: 1.6082\n",
            "Epoch 5/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 483ms/step - accuracy: 0.4695 - loss: 1.0600 - val_accuracy: 0.5771 - val_loss: 0.9162\n",
            "Epoch 6/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 518ms/step - accuracy: 0.5309 - loss: 0.8941 - val_accuracy: 0.6073 - val_loss: 0.9426\n",
            "Epoch 7/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 474ms/step - accuracy: 0.5308 - loss: 0.8730 - val_accuracy: 0.6417 - val_loss: 0.8252\n",
            "Epoch 8/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 472ms/step - accuracy: 0.5356 - loss: 0.8343 - val_accuracy: 0.6438 - val_loss: 0.7702\n",
            "Epoch 9/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 483ms/step - accuracy: 0.5506 - loss: 0.8481 - val_accuracy: 0.5490 - val_loss: 0.9167\n",
            "Epoch 10/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 478ms/step - accuracy: 0.5247 - loss: 0.8933 - val_accuracy: 0.6229 - val_loss: 0.8665\n",
            "Epoch 11/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 474ms/step - accuracy: 0.5607 - loss: 0.8177 - val_accuracy: 0.5854 - val_loss: 0.8320\n",
            "Epoch 12/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 470ms/step - accuracy: 0.5719 - loss: 0.7427 - val_accuracy: 0.6531 - val_loss: 0.7579\n",
            "Epoch 13/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 479ms/step - accuracy: 0.6252 - loss: 0.6584 - val_accuracy: 0.5583 - val_loss: 1.0624\n",
            "Epoch 14/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 471ms/step - accuracy: 0.5874 - loss: 0.7453 - val_accuracy: 0.6750 - val_loss: 0.7407\n",
            "Epoch 15/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 462ms/step - accuracy: 0.6239 - loss: 0.6772 - val_accuracy: 0.6719 - val_loss: 0.7647\n",
            "Epoch 16/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 486ms/step - accuracy: 0.6412 - loss: 0.6609 - val_accuracy: 0.6583 - val_loss: 0.7645\n",
            "Epoch 17/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 453ms/step - accuracy: 0.6189 - loss: 0.7380 - val_accuracy: 0.5417 - val_loss: 1.1658\n",
            "Epoch 18/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 464ms/step - accuracy: 0.6129 - loss: 0.7075 - val_accuracy: 0.6594 - val_loss: 0.7442\n",
            "Epoch 19/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 457ms/step - accuracy: 0.6157 - loss: 0.6695 - val_accuracy: 0.6750 - val_loss: 0.7111\n",
            "Epoch 20/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 461ms/step - accuracy: 0.6257 - loss: 0.6354 - val_accuracy: 0.6354 - val_loss: 0.7663\n",
            "Epoch 21/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 487ms/step - accuracy: 0.6451 - loss: 0.6023 - val_accuracy: 0.6812 - val_loss: 0.7029\n",
            "Epoch 22/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 501ms/step - accuracy: 0.6500 - loss: 0.6647 - val_accuracy: 0.7135 - val_loss: 0.6535\n",
            "Epoch 23/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 484ms/step - accuracy: 0.6589 - loss: 0.5868 - val_accuracy: 0.7042 - val_loss: 0.6641\n",
            "Epoch 24/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 478ms/step - accuracy: 0.6403 - loss: 0.5999 - val_accuracy: 0.6948 - val_loss: 0.6799\n",
            "Epoch 25/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 468ms/step - accuracy: 0.6402 - loss: 0.5993 - val_accuracy: 0.6781 - val_loss: 0.6982\n",
            "Epoch 26/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 478ms/step - accuracy: 0.6247 - loss: 0.6348 - val_accuracy: 0.7125 - val_loss: 0.6334\n",
            "Epoch 27/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 466ms/step - accuracy: 0.6397 - loss: 0.6349 - val_accuracy: 0.6698 - val_loss: 0.7005\n",
            "Epoch 28/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 467ms/step - accuracy: 0.6559 - loss: 0.6291 - val_accuracy: 0.6656 - val_loss: 0.7072\n",
            "Epoch 29/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 465ms/step - accuracy: 0.6572 - loss: 0.5827 - val_accuracy: 0.6875 - val_loss: 0.6825\n",
            "Epoch 30/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 481ms/step - accuracy: 0.6522 - loss: 0.5839 - val_accuracy: 0.7031 - val_loss: 0.6829\n",
            "Epoch 31/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 461ms/step - accuracy: 0.6546 - loss: 0.6063 - val_accuracy: 0.7073 - val_loss: 0.6535\n",
            "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 13s/step - accuracy: 0.6750 - loss: 0.6806"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HsNkjAHojC7C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}