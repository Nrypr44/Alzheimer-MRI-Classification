{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# ğŸ“ KlasÃ¶r yollarÄ±\n",
        "original_train_path = \"/content/drive/MyDrive/Alzheimer_dataset/Splitted_OriginalDataset/train\"\n",
        "augmented_dir = \"/content/drive/MyDrive/Alzheimer_dataset/Custom_Augmented_Train\"\n",
        "os.makedirs(augmented_dir, exist_ok=True)\n",
        "\n",
        "# âœ… Augmentasyon sadece bu sÄ±nÄ±flara uygulanacak\n",
        "target_classes = ['ModerateDemented', 'MildDemented']\n",
        "\n",
        "# ğŸ”„ Augmentasyon ayarlarÄ±\n",
        "augmenter = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# âœ¨ Her sÄ±nÄ±ftan gÃ¶rÃ¼ntÃ¼ler augment edilir ve kaydedilir\n",
        "for class_name in target_classes:\n",
        "    source_dir = os.path.join(original_train_path, class_name)\n",
        "    save_dir = os.path.join(augmented_dir, class_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    files = os.listdir(source_dir)[:20]  # Ã–rnek: ilk 20 gÃ¶rÃ¼ntÃ¼\n",
        "    for fname in files:\n",
        "        img_path = os.path.join(source_dir, fname)\n",
        "        img = load_img(img_path, target_size=(176, 208))\n",
        "        x = img_to_array(img)\n",
        "        x = x.reshape((1,) + x.shape)\n",
        "\n",
        "        prefix = fname.split('.')[0]\n",
        "        for i, batch in enumerate(augmenter.flow(x, batch_size=1, save_to_dir=save_dir,\n",
        "                                                 save_prefix=prefix, save_format='jpg')):\n",
        "            if i >= 5:  # Her bir gÃ¶rselden 5 tane yeni Ã¼ret\n",
        "                break\n"
      ],
      "metadata": {
        "id": "DldLNMSO5e-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Updated import statement to reflect the Keras 3 API changes.\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# ğŸ“ Veri seti yollarÄ±\n",
        "train_dir = \"/content/drive/MyDrive/Alzheimer_dataset/Splitted_OriginalDataset/train\"\n",
        "val_dir = \"/content/drive/MyDrive/Alzheimer_dataset/Splitted_OriginalDataset/val\"\n",
        "test_dir = \"/content/drive/MyDrive/Alzheimer_dataset/Splitted_OriginalDataset/test\"\n",
        "\n",
        "# ğŸ”„ Veri hazÄ±rlÄ±ÄŸÄ± ve artÄ±rma\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # GÃ¶rÃ¼ntÃ¼lerin normalize edilmesi\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=(176, 208), batch_size=32, class_mode='sparse', color_mode='rgb'\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir, target_size=(176, 208), batch_size=32, class_mode='sparse', color_mode='rgb'\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=(176, 208), batch_size=32, class_mode='sparse', color_mode='rgb'\n",
        ")\n",
        "\n",
        "# ğŸ—ï¸ Model yapÄ±sÄ± (VGG19)\n",
        "base_model = VGG19(include_top=False, weights='imagenet', input_shape=(176, 208, 3))\n",
        "base_model.trainable = False  # Ä°lk baÅŸta sadece Ã¼st katmanlarÄ± eÄŸiteceÄŸiz\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "# ğŸ“‰ Callbacks\n",
        "tensorboard_cb = TensorBoard(log_dir='/content/drive/MyDrive/Alzheimer_dataset/logs')\n",
        "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# ğŸ¯ SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± hesaplama\n",
        "# ğŸ¯ SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± hesaplama\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),  # Changed to np.unique(train_generator.classes) to get unique class labels as a NumPy array\n",
        "    y=train_generator.classes\n",
        ")\n",
        "\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# ğŸš€ Modeli eÄŸit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[tensorboard_cb, early_stopping_cb]\n",
        ")\n",
        "\n",
        "# ğŸ¯ Model deÄŸerlendirmesi\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
        "\n",
        "# ğŸ¯ Test verisi Ã¼zerinde tahmin ve sonuÃ§ raporu\n",
        "test_predictions = model.predict(test_generator)\n",
        "test_predictions = tf.argmax(test_predictions, axis=1)\n",
        "print(classification_report(test_generator.classes, test_predictions))\n",
        "\n",
        "# ğŸ’¾ Modeli kaydet\n",
        "model.save(\"/content/drive/MyDrive/Alzheimer_dataset/final_model_vgg19.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrP3YVGKBwTe",
        "outputId": "2bed847c-00b8-4c12-d5ad-a0b8644801d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4479 images belonging to 4 classes.\n",
            "Found 960 images belonging to 4 classes.\n",
            "Found 961 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 570ms/step - accuracy: 0.3049 - loss: 2.9330 - val_accuracy: 0.3667 - val_loss: 1.3768\n",
            "Epoch 2/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 495ms/step - accuracy: 0.4318 - loss: 1.1664 - val_accuracy: 0.5031 - val_loss: 1.0134\n",
            "Epoch 3/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 480ms/step - accuracy: 0.4729 - loss: 1.1582 - val_accuracy: 0.5521 - val_loss: 0.8927\n",
            "Epoch 4/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 479ms/step - accuracy: 0.5172 - loss: 1.1013 - val_accuracy: 0.3531 - val_loss: 1.6082\n",
            "Epoch 5/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 483ms/step - accuracy: 0.4695 - loss: 1.0600 - val_accuracy: 0.5771 - val_loss: 0.9162\n",
            "Epoch 6/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 518ms/step - accuracy: 0.5309 - loss: 0.8941 - val_accuracy: 0.6073 - val_loss: 0.9426\n",
            "Epoch 7/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 474ms/step - accuracy: 0.5308 - loss: 0.8730 - val_accuracy: 0.6417 - val_loss: 0.8252\n",
            "Epoch 8/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 472ms/step - accuracy: 0.5356 - loss: 0.8343 - val_accuracy: 0.6438 - val_loss: 0.7702\n",
            "Epoch 9/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 483ms/step - accuracy: 0.5506 - loss: 0.8481 - val_accuracy: 0.5490 - val_loss: 0.9167\n",
            "Epoch 10/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 478ms/step - accuracy: 0.5247 - loss: 0.8933 - val_accuracy: 0.6229 - val_loss: 0.8665\n",
            "Epoch 11/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 474ms/step - accuracy: 0.5607 - loss: 0.8177 - val_accuracy: 0.5854 - val_loss: 0.8320\n",
            "Epoch 12/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 470ms/step - accuracy: 0.5719 - loss: 0.7427 - val_accuracy: 0.6531 - val_loss: 0.7579\n",
            "Epoch 13/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 479ms/step - accuracy: 0.6252 - loss: 0.6584 - val_accuracy: 0.5583 - val_loss: 1.0624\n",
            "Epoch 14/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 471ms/step - accuracy: 0.5874 - loss: 0.7453 - val_accuracy: 0.6750 - val_loss: 0.7407\n",
            "Epoch 15/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 462ms/step - accuracy: 0.6239 - loss: 0.6772 - val_accuracy: 0.6719 - val_loss: 0.7647\n",
            "Epoch 16/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 486ms/step - accuracy: 0.6412 - loss: 0.6609 - val_accuracy: 0.6583 - val_loss: 0.7645\n",
            "Epoch 17/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 453ms/step - accuracy: 0.6189 - loss: 0.7380 - val_accuracy: 0.5417 - val_loss: 1.1658\n",
            "Epoch 18/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 464ms/step - accuracy: 0.6129 - loss: 0.7075 - val_accuracy: 0.6594 - val_loss: 0.7442\n",
            "Epoch 19/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 457ms/step - accuracy: 0.6157 - loss: 0.6695 - val_accuracy: 0.6750 - val_loss: 0.7111\n",
            "Epoch 20/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 461ms/step - accuracy: 0.6257 - loss: 0.6354 - val_accuracy: 0.6354 - val_loss: 0.7663\n",
            "Epoch 21/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 487ms/step - accuracy: 0.6451 - loss: 0.6023 - val_accuracy: 0.6812 - val_loss: 0.7029\n",
            "Epoch 22/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 501ms/step - accuracy: 0.6500 - loss: 0.6647 - val_accuracy: 0.7135 - val_loss: 0.6535\n",
            "Epoch 23/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 484ms/step - accuracy: 0.6589 - loss: 0.5868 - val_accuracy: 0.7042 - val_loss: 0.6641\n",
            "Epoch 24/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 478ms/step - accuracy: 0.6403 - loss: 0.5999 - val_accuracy: 0.6948 - val_loss: 0.6799\n",
            "Epoch 25/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 468ms/step - accuracy: 0.6402 - loss: 0.5993 - val_accuracy: 0.6781 - val_loss: 0.6982\n",
            "Epoch 26/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 478ms/step - accuracy: 0.6247 - loss: 0.6348 - val_accuracy: 0.7125 - val_loss: 0.6334\n",
            "Epoch 27/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 466ms/step - accuracy: 0.6397 - loss: 0.6349 - val_accuracy: 0.6698 - val_loss: 0.7005\n",
            "Epoch 28/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 467ms/step - accuracy: 0.6559 - loss: 0.6291 - val_accuracy: 0.6656 - val_loss: 0.7072\n",
            "Epoch 29/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 465ms/step - accuracy: 0.6572 - loss: 0.5827 - val_accuracy: 0.6875 - val_loss: 0.6825\n",
            "Epoch 30/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 481ms/step - accuracy: 0.6522 - loss: 0.5839 - val_accuracy: 0.7031 - val_loss: 0.6829\n",
            "Epoch 31/50\n",
            "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 461ms/step - accuracy: 0.6546 - loss: 0.6063 - val_accuracy: 0.7073 - val_loss: 0.6535\n",
            "\u001b[1m23/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”\u001b[0m \u001b[1m1:42\u001b[0m 13s/step - accuracy: 0.6750 - loss: 0.6806"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HsNkjAHojC7C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}